# ML/DS Interview Guide
This repo is a checklist to prepare for ML/Data Science interviews, at each section I listed the topics you need to cover and a link to a source which oes over the topic comprehensively.


## Statistics
* Central Limit Theorem
* Bayes' theorem
## Linear Algebra
This section is needed the most for positions related to NLP and Recommender engines.
* Eigenvalues and Eigenvectors
* Kernel, Range, Nullity, Rank
* Singular Value Decomposition
* Matrix Factorization

To learn about this topic check [Linear Algebra by Cherney et. al.](https://www.math.ucdavis.edu/~linear/linear-guest.pdf) or [khan academy website](https://www.khanacademy.org/math/linear-algebra).
## Data Preparation
### Feature Engineering
* typical groupby-agg,
* counting,
* [categorical encoding](https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159) (Ordinal, OneHot, Binary, BaseN, Hashing),
* count vector,
* FM/FFM,
* NN and
* out of fold model
### Feature Selection
* All Subsets
* Filter Methods -- Chi squared test, information gain and correlation coefficient scores
* Wrapper Methods -- Stepwise Procedures (backward and forward)
* Embedded Methods -- LASSO, Elastic Net and Ridge Regression

Here is a good easy read from [DataCamp](https://www.datacamp.com/community/tutorials/feature-selection-python)
![alt text](https://openclipart.org/download/275692/1489798288.svg)

* Note that PCA is a dimensionality reduction method but not feature selection method
[This datacamp link has whatever you need to know](https://www.datacamp.com/community/tutorials/feature-selection-python)
## Algorithms
### Classification
### Clustering
#### Hard Clustering
* K-means Clustering
* Hierarchical Clustering
#### Soft Clustering
* C-means Clustering
* GMM
### Regression

## Model Evaluation, Model Selection
Most of this section is taken from [this paper](https://arxiv.org/pdf/1811.12808.pdf)

## Coding
